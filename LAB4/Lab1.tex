\documentclass[titlepage, 11pt]{scrartcl}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsmath, amsthm, amsfonts}
\usepackage{graphics}
\usepackage{skull}
\usepackage{mathabx}
\usepackage{float}
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{latexsym}
\usepackage{newlfont}
\usepackage{epstopdf}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{caption}
\usepackage{multirow}
\usepackage{graphics}
\usepackage{wrapfig}
\usepackage[rflt]{floatflt}
\usepackage{multicol}

\hypersetup{colorlinks,%
	citecolor=black,%
	filecolor=cyan,%
	linkcolor=blue!60,%
	urlcolor=cyan}

\title{
    \normalfont\normalsize
    {\huge Modelos de Optimización\\
    		\textbf{Laboratorio 4}}
    \vspace{12pt}
}

\author{Osmany P\'erez Rodr\'iguez\\
		Enrique Mart\'inez Gonz\'alez\\
		Carmen Irene Cabrera Rodr\'iguez\\
		\textbf{Grupo C412 Equipo 9}}
	

\date{}

\begin{document}
    \maketitle 
    
	\section{Métodos numéricos para problemas de optimización no lineales}    
		
	Solucionar problemas de optimización que involucran funciones no lineales (ya sea la función objetivo, o las restricciones a las que está sujeto el problema) es un proceso complicado dado que, en la mayoría de los casos, requiere la solución de sistemas complejos de ecuaciones no lineales. De hecho, en la práctica, hallar el mínimo o máximo global de unafunción no-lineal cualquiera es un problema abierto en matemáticas. Los métodosexistentes sólo obtienen mínimo locales.
	
	Entre los métodos numéricos que existen con este propósito se pueden mencionar:
	\begin{itemize}
		\item Método de máximo descenso
		\item Método de Newton
		\item Métodos de Quasi-Newton(BFGS, DFP, Gradiente Conjugado)
		\item Método de región de confianza
		\item Método de penalidad
		\item Método de barrera
		\item Método de secuenciación cuadrática
	\end{itemize}

	En particular, los métodos que se tomaron en consideración para la solución de los problemas orientados fueron los últimos tres, puesto que estos son métodos para problemas con restricciones, como es el caso; y los otros métodos son para problemas irrestrictos. Se verá a continuación un breve análisis de estos tres algoritmos.
	
	Suponga que se tiene el problema de programación no lineal:
	\begin{align*}
		min  &f(x)\\
		s.a: &g_j(x) \leq 0, j = 1, \ldots , m\\
		&h_i(x) = 0, i = 1, \ldots, n
	\end{align*}
	Con $f, g, h \in C^1(\Omega)$; considerando a $\Omega$ el conjunto de soluciones factibles; es decir, $\Omega = \{x \in \mathbb{R}: h_i(x) = 0 , g_j(x) \leq 0\}$
	
	\subsection{Método de Penalidad}
	La idea de este método es minimizar $f$ sobre $\mathbb{R}^n$, aplicándole una penalización a los puntos que no están en $\Omega$. 
	
	Se define la función de penalización cuadrática como:
	\begin{equation*}
		Q(x, c) = f(x) + c \sum_{i = 1}^{n}h_i^2(x) + c \sum_{j = 1}^{m}g_j^+(x)^2
	\end{equation*}
	Donde $c$ es el \textit{parámetro de penalización} y $g_j^+ = max\{0, g_j(x)\}$. Se considera la secuencia $\{c_k\}$ tal que $c_k \rightarrow \infty$ cuando $k \rightarrow \infty$; a medida que aumente $c$, la violación de las restricciones será castigada con mayor severidad. Luego basta hallar el minimizador $x_k$ de $Q(x, c_k)$ para cada $k$ utilizando algún método de optimización irrestricto. Cualquier punto límite de la sucesión de puntos $\{x_k\}_{k \in \mathbb{N}}$ obtenidos con el método de penalidad es solución del problema $min f(x), x\in \Omega$.
	
	Se debe tener en cuenta a la hora de aplicar este método, que si se aumenta el valor de $c_k$ demasiado rápido, puede causar inestabilidad numérica y divergencia de los métodos de optimización; por ello, se debe comenzar con un $c$ pequeño y aumentarlo de forma gradual.
	
	Este método resulta de gran utilidad, puesto que es aplicable con generalidad a problemas de optimización con restricciones, ya sean de igualdad o desigualdad. Además, el punto inicial se puede seleccionar de forma arbitraria, no necesita pertenecer al conjunto de soluciones factibles. No obstante, dado que el método itera por la región no factible del problema, tanto el costo como las funciones de restricción pueden estar indefinidos. Además, si el proceso de iteración termina de forma prematura (por haber alcanzado el másimo número de iteraciones) el punto obtenido finalmente puede no ser factible y por tanto, no sería solución del problema.
	
	\subsubsection{Implementación}
	Dadas las funciones $f, h_i, g_j$, el punto inicial $x_0 \in \mathbb{R}^n$ y $c_0 \in \mathbb{R}, \alpha \in \mathbb{R}_{> 1}, \varepsilon, k_{max}$ se presenta el siguiente pseudocódigo para el algoritmo:
	\begin{enumerate}
		\item Definir $Q(x, c_k)$
		\item $x_{k + 1} = min Q(x, c_k)$ utilizando método de optimización irrestricta que asume como punto inicial $x_k$
		\item Si $x_{k + 1} \in \Omega \Rightarrow$ PARAR
		\item Si no: 
		\begin{align*}
			c_{k + 1} &= \alpha c_k\\
			k &= k + 1
		\end{align*}
		\item Si $||x_k - x_{k+ 1}|| > \varepsilon$ y $k \leq k_max$ repetir el proceso desde el punto 1. De lo contrario PARAR.
	\end{enumerate}

	El código que contiene la implementación de este método se puede acceder a través del siguiente \href{methods.py}{enlace}.
	
	\subsection{Método de Barrera}
	A diferencia del algoritmo anterior, la idea del método de barrera es aproximarse a los puntos de la frontera de $\Omega$ desde su interior. Si se consigue una función $B$ tal que :
	\begin{itemize}
		\item $B$ es continua
		\item $B(x) \geq 0$
		\item $B(x) \rightarrow \infty$ cuando $x$ se acerca a la frontera de $\Omega$
	\end{itemize}
	Entonces se puede resolver el problema $min f(x) + \mu B(x)$ con métodos de optimización irrestricta. entre las funciones de barrera más comunes está $B(x) = \sum_{i}-\frac{1}{g_i(x)}$, que fue la utilizada en la implementación del método. De este modo, se transforma el problema en minimizar la función
	\begin{equation*}
		R(x, \mu) = f(x) + \mu B(x)
	\end{equation*}
	Análogo al método de penalidad, cualquier punto límite de la sucesión de puntos $\{x_k\}_{k \in \mathbb{N}}$ generada por este método es solución del problema.
	
	Note que dado que el algoritmo se mueve por los puntos interiores de $\Omega$, este método es aplicable a problemas con restricciones dadas por desigualdades, ya que en particular, es necesario que $int \Omega \neq \emptyset$. En particular, este método es aplicable a los ejercicios que se resolverán a continuación, puesto que las restricciones de los mismos están dadas por desigualdades.
	
	Otra ventaja que provee la utilización de este método, es que típicamente se soluciona usando métodos de Newton para problemas irrestrictos, que convergen rápidamente si se inicializa cerca de la solución.
	
		\subsubsection{Implementación}
		La implementación de este método es análoga a la del método de penalidad.
		
	Dadas las funciones $f, g_i$, el punto inicial $x_0 \in \mathbb{R}^n$ y $\mu_0 \in \mathbb{R}, \alpha \in \mathbb{R}_{< 1}, \varepsilon, k_{max}$ se presenta el siguiente pseudocódigo para el algoritmo:
	\begin{enumerate}
		\item Definir $R(x, \mu_k)$
		\item $x_{k + 1} = min R(x, \mu_k)$ utilizando método de optimización irrestricta que asume como punto inicial $x_k$
		\item \begin{align*}
		\mu_{k + 1} &= \alpha \mu_k\\
		k &= k + 1
		\end{align*}
		\item Si $||x_k - x_{k+ 1}|| > \varepsilon$ y $k \leq k_max$ repetir el proceso desde el punto 1. De lo contrario PARAR.
	\end{enumerate}
	Se puede acceder al código que contiene la implementación a través del siguiente \href{methods.py}{enlace}.
	
	Ambos métodos anteriores requieren solucionar un subproblema de optimización irrestricto. En ambos casos se decidió utilizar el método BFGS, una variante de los métodos Quasi-Newton.
	
	\subsubsection{Método BFGS (Broyden-Fletcher-Goldfarb-Shanno)}
		El algoritmo de Newton tiene la ventaja de lograr la convergencia cuadrática si el punto inicial está cerca del óptimo; de lo contrario, la dirección puede no ser de descenso y diverger. Además, en cada iteración es necesario calcular la inversa de la matriz hessiana de $f$ en $x_k$ de manera exacta, lo cual es costoso computacionalmente. Por esta razón se proponen los métodos de QuasiNewton, que permiten construir iterativamente la matriz $S_k$ de manera que se verifique las siguientes condiciones:
		\begin{itemize}
			\item Definida positiva: Si $S_k$ es definida positiva $\Rightarrow S_{k+1}$ también lo es
			\item Aproximación de la matriz hessiana inversa de $f$: $x_k \rightarrow x^*, S_k \rightarrow [\nabla^2f(x^*)]^{-1}$ para $k \rightarrow \infty$
		\end{itemize}
	
		La forma de construir estos métodos asegura:
		\begin{itemize}
			\item Convergencia global
			\item Rapidez de convergencia mayor que lineal
			\item Convergencia a un mínimo local
		\end{itemize}
		Puede encontrar una implementación del método en el siguiente \href{methods.py}{enalce}; no obstante, para la resolución de los ejercicios propuestos se utilizó la función \textit{minimize} de la biblioteca de Python \textit{Scipy.minimize}, pasando como argumento el solver \textit{'BFGS'}. Se profundizará un poco en esta herramienta más adelante.
		
	\subsection{Método de Secuenciación Cuadrática}
	Los métodos de secuenciación cuadrática (\textit{SQP - Sequential Quadratic Programming}) son altamente utilizados en la vida real, al ser capaces de manejar cualquier nicel de no linealidad, incluidas las restricciones. Sin embargo, su principal desventaja es que el método incorpora numerosas derivaciones, que probablemente se necesiten trabajar de forma analítica, lo que resulta un problema al trabajar con muchas variables en problemas muy grandes.
	
	La idea de este método consiste en transformar el problema dado en los problemas cuadráticos $QP(x_k, \lambda_k, \mu_k)$ dados por:
	\begin{align*}
		min &f(x_k) + \nabla f(x)^Td + \frac{1}{2}d^T[\nabla^2L_k]d\\
		s.a &h_i(x_k) + \nabla h_i(x_k)^Td = 0; i = 1, \ldots, n\\
		&g_j(x_k) + \nabla g_j(x_k)^T d \leq 0; j 0 1, \ldots, m
	\end{align*}
	
	donde
	\begin{equation*}
		\nabla^2 L_k = \nabla^2f(x_k) + \sum_{i = 1}^{n}(\lambda_k)_i\nabla^2h_i(x_k) + \sum_{j = 1}^{m}(\mu_k)_j\nabla^2g_j(x_k)
	\end{equation*}
	
	
	Dada la complejidad y el costo de este algoritmo es mejor utilizarlo en problemas de alta no linealidad en la función objetivo y sus restricciones; que no es el caso de los problemas propuestos. No obstante, se brinda una solución para los problemas con este método a través de la biblioteca \textit{Scipy} de Python; utilizando como \textit{solver} el método \textit{'SLSQP'}.
	
	\subsection{SciPy.optimize-minimize}
	Scipy es un ecosistema basado en Python de código abierto destinado a software matemáticos, a la ciencia y la ingeniería. En particular, la biblioteca \textit{optimize} de SciPy provee métodos para la minimización (o maximización) de funciones objetivos, sujetas o no a restricciones. Incluye solucionadores para problemas no lineales (con soporte para algoritmos de optimización local y global), programación lineal, para hallar raíces, entre otros.
	
	El método utilizado para la solución de los problemas fue \textit{minimize}; que permite pasar como parámetros:
	\begin{itemize}
		\item la función objetivo a ser minimizada
		\item $x_0$ el punto inicial
		\item \textit{method}: tipo de solucionador. Presenta variados tipos de solucionadores, entre ellos: BFGS, que fue el utilizado en los métodos de penalidad y barrera para resolver el problema irrestricto, y SLSQP. Este últimmo minimiza la función dada utilizando el método \textit{Sequential Least Squares Quadratic Programming}, una de las variaciones de los métodos de secuenciación cuadrática.
		\item la matriz jacobiana de la función objetivo
		\item la matriz hessiana de la función objetivo
		\item las restricciones
		\item \textit{options} entre las cuales se puede setear, por ejemplo, la máxima cantidad de iteraciones que realizará el algoritmo.
	\end{itemize}
	Para más información con respecto a esta herramienta puede consultar la documentación a través del siguiente \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html}{enlace}
	
\end{document}